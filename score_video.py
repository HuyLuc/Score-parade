"""
Script ƒë∆°n gi·∫£n ƒë·ªÉ:
1. T·∫°o golden template t·ª´ video (ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng)
2. ƒê√°nh gi√° video test so v·ªõi golden template
"""
import sys
from pathlib import Path
import numpy as np
import json
import pickle
from typing import List, Dict
import cv2

# Add backend to path
sys.path.insert(0, str(Path(__file__).parent))

from backend.app.services.pose_service import PoseService
from backend.app.services.video_utils import load_video, get_frames, validate_video
from backend.app.services.geometry import (
    calculate_arm_angle, calculate_leg_angle,
    calculate_arm_height, calculate_leg_height,
    calculate_head_angle, calculate_torso_stability
)
from backend.app.controllers.ai_controller import AIController
from backend.app.services.scoring_service import ScoringService
from backend.app.config import GOLDEN_TEMPLATE_DIR, INPUT_VIDEOS_DIR, OUTPUT_DIR


def create_golden_template(video_path: Path, output_dir: Path = None):
    """
    T·∫°o golden template t·ª´ video
    
    Args:
        video_path: ƒê∆∞·ªùng d·∫´n video golden
        output_dir: Th∆∞ m·ª•c l∆∞u output (m·∫∑c ƒë·ªãnh: data/golden_template)
    """
    if output_dir is None:
        output_dir = GOLDEN_TEMPLATE_DIR
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"üìπ ƒêang x·ª≠ l√Ω video golden: {video_path}")
    
    # Validate video tr∆∞·ªõc khi x·ª≠ l√Ω ƒë·ªÉ tr√°nh crash do file l·ªói/corrupt
    is_valid, error_message = validate_video(video_path)
    if not is_valid:
        print(f"‚ùå Video kh√¥ng h·ª£p l·ªá: {error_message}")
        return None

    cap = None
    try:
    # Load video
    cap, metadata = load_video(video_path)
    print(f"   FPS: {metadata['fps']}, K√≠ch th∆∞·ªõc: {metadata['width']}x{metadata['height']}")
    
    # Kh·ªüi t·∫°o pose service
    pose_service = PoseService()
    
    # L∆∞u tr·ªØ keypoints v√† ƒë·∫∑c tr∆∞ng
    all_keypoints = []
    features = {
        "arm_angle": {"left": [], "right": []},
        "leg_angle": {"left": [], "right": []},
        "arm_height": {"left": [], "right": []},
        "leg_height": {"left": [], "right": []},
        "head_angle": [],
        "torso_stability": []
    }
    
    frame_count = 0
    valid_frames = 0
    
    print("   ƒêang ph√¢n t√≠ch t·ª´ng frame...")
    for frame in get_frames(cap):
        frame_count += 1
        
        # Detect pose
        keypoints_list = pose_service.predict(frame)
        
        if len(keypoints_list) == 0:
            continue
        
        # L·∫•y ng∆∞·ªùi ƒë·∫ßu ti√™n
        keypoints = keypoints_list[0]
        
        # Ki·ªÉm tra keypoints h·ª£p l·ªá (c√≥ ƒë·ªß 17 keypoints v√† confidence)
        if keypoints.shape[0] < 17 or keypoints.shape[1] < 3:
            continue
        
        # L∆∞u keypoints
        all_keypoints.append(keypoints.copy())
        
        # T√≠nh to√°n ƒë·∫∑c tr∆∞ng
        # G√≥c tay
        left_arm_angle = calculate_arm_angle(keypoints, "left")
        right_arm_angle = calculate_arm_angle(keypoints, "right")
        if left_arm_angle is not None:
            features["arm_angle"]["left"].append(left_arm_angle)
        if right_arm_angle is not None:
            features["arm_angle"]["right"].append(right_arm_angle)
        
        # G√≥c ch√¢n
        left_leg_angle = calculate_leg_angle(keypoints, "left")
        right_leg_angle = calculate_leg_angle(keypoints, "right")
        if left_leg_angle is not None:
            features["leg_angle"]["left"].append(left_leg_angle)
        if right_leg_angle is not None:
            features["leg_angle"]["right"].append(right_leg_angle)
        
        # ƒê·ªô cao tay
        left_arm_h = calculate_arm_height(keypoints, "left")
        right_arm_h = calculate_arm_height(keypoints, "right")
        if left_arm_h is not None:
            features["arm_height"]["left"].append(left_arm_h)
        if right_arm_h is not None:
            features["arm_height"]["right"].append(right_arm_h)
        
        # ƒê·ªô cao ch√¢n
        left_leg_h = calculate_leg_height(keypoints, "left")
        right_leg_h = calculate_leg_height(keypoints, "right")
        if left_leg_h is not None:
            features["leg_height"]["left"].append(left_leg_h)
        if right_leg_h is not None:
            features["leg_height"]["right"].append(right_leg_h)
        
        # G√≥c ƒë·∫ßu
        head_angle = calculate_head_angle(keypoints)
        if head_angle is not None:
            features["head_angle"].append(head_angle)
        
        # ·ªîn ƒë·ªãnh th√¢n - s·∫Ω t√≠nh sau khi c√≥ ƒë·ªß frames
        # (torso_stability c·∫ßn nhi·ªÅu frames ƒë·ªÉ t√≠nh variance)
        
        valid_frames += 1
        
        if frame_count % 30 == 0:
            print(f"   ƒê√£ x·ª≠ l√Ω {frame_count} frames...")
    finally:
        if cap is not None:
    cap.release()
    
    if valid_frames == 0:
        print("‚ùå Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi n√†o trong video!")
        return None
    
    print(f"‚úÖ ƒê√£ ph√¢n t√≠ch {valid_frames}/{frame_count} frames h·ª£p l·ªá")
    
    # T√≠nh torso_stability sau khi c√≥ ƒë·ªß keypoints
    if len(all_keypoints) > 1:
        try:
            keypoints_array = np.array(all_keypoints)  # [n_frames, 17, 3]
            torso_stab = calculate_torso_stability(keypoints_array)
            if torso_stab is not None:
                features["torso_stability"].append(torso_stab)
        except Exception as e:
            print(f"   C·∫£nh b√°o: Kh√¥ng th·ªÉ t√≠nh torso_stability: {e}")
    
    # T√≠nh th·ªëng k√™ (mean, std) cho m·ªói ƒë·∫∑c tr∆∞ng
    statistics = {}
    for feature_name, feature_data in features.items():
        if isinstance(feature_data, dict):
            statistics[feature_name] = {}
            for side, values in feature_data.items():
                if len(values) > 0:
                    statistics[feature_name][side] = {
                        "mean": float(np.mean(values)),
                        "std": float(np.std(values)),
                        "min": float(np.min(values)),
                        "max": float(np.max(values)),
                        "count": len(values)
                    }
        else:
            if len(feature_data) > 0:
                statistics[feature_name] = {
                    "mean": float(np.mean(feature_data)),
                    "std": float(np.std(feature_data)),
                    "min": float(np.min(feature_data)),
                    "max": float(np.max(feature_data)),
                    "count": len(feature_data)
                }
    
    # T·∫°o golden profile
    golden_profile = {
        "video_path": str(video_path),
        "metadata": metadata,
        "statistics": statistics,
        "total_frames": frame_count,
        "valid_frames": valid_frames
    }
    
    # L∆∞u golden profile
    profile_path = output_dir / "golden_profile.json"
    with open(profile_path, 'w', encoding='utf-8') as f:
        json.dump(golden_profile, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ ƒê√£ l∆∞u golden profile: {profile_path}")
    
    # L∆∞u keypoints
    skeleton_path = output_dir / "golden_skeleton.pkl"
    with open(skeleton_path, 'wb') as f:
        pickle.dump({
            "keypoints": np.array(all_keypoints),
            "valid_skeletons": np.array(all_keypoints)
        }, f)
    print(f"‚úÖ ƒê√£ l∆∞u golden skeleton: {skeleton_path}")
    
    return golden_profile


def evaluate_video(test_video_path: Path, golden_template_dir: Path = None):
    """
    ƒê√°nh gi√° video test so v·ªõi golden template
    
    Args:
        test_video_path: ƒê∆∞·ªùng d·∫´n video test
        golden_template_dir: Th∆∞ m·ª•c ch·ª©a golden template (m·∫∑c ƒë·ªãnh: data/golden_template)
    """
    import logging
    logger = logging.getLogger(__name__)
    
    if golden_template_dir is None:
        golden_template_dir = GOLDEN_TEMPLATE_DIR
    
    print(f"\nüìπ ƒêang ƒë√°nh gi√° video test: {test_video_path}")
    
    # Ki·ªÉm tra golden template
    profile_path = golden_template_dir / "golden_profile.json"
    if not profile_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y golden profile: {profile_path}")
        print("   H√£y ch·∫°y t·∫°o golden template tr∆∞·ªõc!")
        return None
    
    # Load video test v·ªõi error handling
    try:
        cap, metadata = load_video(test_video_path)
        print(f"   FPS: {metadata['fps']}, K√≠ch th∆∞·ªõc: {metadata['width']}x{metadata['height']}")
    except FileNotFoundError as e:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file video: {e}")
        logger.error(f"Video file not found: {test_video_path}", exc_info=True)
        return None
    except ValueError as e:
        print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video: {e}")
        logger.error(f"Cannot open video: {test_video_path}", exc_info=True)
        return None
    except cv2.error as e:
        print(f"‚ùå L·ªói OpenCV khi ƒë·ªçc video: {e}")
        logger.error(f"OpenCV error reading video: {test_video_path}", exc_info=True)
        return None
    except Exception as e:
        print(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh khi load video: {type(e).__name__}: {e}")
        logger.error(f"Unexpected error loading video: {test_video_path}", exc_info=True)
        return None
    
    # Kh·ªüi t·∫°o services
    pose_service = PoseService()
    ai_controller = AIController(pose_service)
    # ƒê√¢y l√† ƒë√°nh gi√° ki·ªÉu "thi" -> d√πng ng∆∞·ª°ng testing
    scoring_service = ScoringService(mode="testing")
    
    # Load golden template
    ai_controller.load_golden_template()
    if ai_controller.golden_profile is None:
        print("‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng load ƒë∆∞·ª£c golden profile, s·∫Ω d√πng ng∆∞·ª°ng m·∫∑c ƒë·ªãnh")
    else:
        print("‚úÖ ƒê√£ load golden template")
    
    # Ph√°t hi·ªán l·ªói t·ª´ng frame
    all_errors = []
    frame_count = 0
    valid_frames = 0
    
    print("   ƒêang ph√¢n t√≠ch t·ª´ng frame...")
    try:
        for frame in get_frames(cap):
            frame_count += 1
            
            # Detect pose
            try:
                keypoints_list = pose_service.predict(frame)
            except Exception as e:
                logger.warning(f"L·ªói khi detect pose t·∫°i frame {frame_count}: {e}")
                continue
            
            if len(keypoints_list) == 0:
                continue
            
            keypoints = keypoints_list[0]
            
            if keypoints.shape[0] < 17 or keypoints.shape[1] < 3:
                continue
            
            # Ph√°t hi·ªán l·ªói
            try:
                errors = ai_controller.detect_posture_errors(
                    keypoints=keypoints,
                    frame_number=frame_count,
                    timestamp=frame_count / metadata['fps']
                )
                all_errors.extend(errors)
                valid_frames += 1
            except Exception as e:
                logger.warning(f"L·ªói khi ph√°t hi·ªán l·ªói t·∫°i frame {frame_count}: {e}")
                continue
            
            if frame_count % 30 == 0:
                print(f"   ƒê√£ x·ª≠ l√Ω {frame_count} frames, ph√°t hi·ªán {len(all_errors)} l·ªói...")
    finally:
        # ƒê·∫£m b·∫£o video capture ƒë∆∞·ª£c ƒë√≥ng ngay c·∫£ khi c√≥ exception
        cap.release()
    
    if valid_frames == 0:
        print("‚ùå Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi n√†o trong video!")
        return None
    
    print(f"‚úÖ ƒê√£ ph√¢n t√≠ch {valid_frames}/{frame_count} frames h·ª£p l·ªá")
    print(f"   T·ªïng s·ªë l·ªói ph√°t hi·ªán (tr∆∞·ªõc khi nh√≥m): {len(all_errors)}")
    
    # Nh√≥m c√°c l·ªói li√™n ti·∫øp th√†nh sequences ƒë·ªÉ tr√°nh ph·∫°t tr√πng l·∫∑p
    from backend.app.services.sequence_comparison import SequenceComparator
    from backend.app.config import SEQUENCE_COMPARISON_CONFIG
    
    sequence_enabled = SEQUENCE_COMPARISON_CONFIG.get("enabled", True)
    if sequence_enabled:
        sequence_comparator = SequenceComparator(
            min_sequence_length=SEQUENCE_COMPARISON_CONFIG.get("min_sequence_length", 5),
            severity_aggregation=SEQUENCE_COMPARISON_CONFIG.get("severity_aggregation", "mean"),
            enabled=True
        )
        grouped_errors = sequence_comparator.group_errors_into_sequences(all_errors)
        print(f"   T·ªïng s·ªë l·ªói sau khi nh√≥m: {len(grouped_errors)}")
        print(f"   Gi·∫£m: {len(all_errors) - len(grouped_errors)} l·ªói ({(len(all_errors) - len(grouped_errors)) / max(len(all_errors), 1) * 100:.1f}%)")
        all_errors = grouped_errors
    
    # T√≠nh ƒëi·ªÉm
    total_deduction = sum(error.get("deduction", 0.0) for error in all_errors)
    initial_score = scoring_service.initial_score
    final_score = max(0.0, initial_score - total_deduction)
    is_passed = scoring_service.is_passed(final_score)
    
    # T·ªïng h·ª£p k·∫øt qu·∫£
    result = {
        "video_path": str(test_video_path),
        "metadata": metadata,
        "total_frames": frame_count,
        "valid_frames": valid_frames,
        "initial_score": initial_score,
        "total_deduction": float(total_deduction),
        "final_score": float(final_score),
        "is_passed": is_passed,
        "total_errors": len(all_errors),
        "errors_by_type": {}
    }
    
    # Nh√≥m l·ªói theo type
    for error in all_errors:
        error_type = error.get("type", "unknown")
        if error_type not in result["errors_by_type"]:
            result["errors_by_type"][error_type] = 0
        result["errors_by_type"][error_type] += 1
    
    # L∆∞u k·∫øt qu·∫£
    output_dir = OUTPUT_DIR / test_video_path.stem
    output_dir.mkdir(parents=True, exist_ok=True)
    
    result_path = output_dir / "evaluation_result.json"
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£: {result_path}")
    
    # In k·∫øt qu·∫£
    print("\n" + "="*60)
    print("K·∫æT QU·∫¢ ƒê√ÅNH GI√Å")
    print("="*60)
    print(f"Video: {test_video_path.name}")
    print(f"ƒêi·ªÉm ban ƒë·∫ßu: {initial_score:.2f}")
    print(f"T·ªïng ƒëi·ªÉm tr·ª´: {total_deduction:.2f}")
    print(f"ƒêi·ªÉm cu·ªëi: {final_score:.2f}")
    print(f"K·∫øt qu·∫£: {'‚úÖ ƒê·∫†T' if is_passed else '‚ùå TR∆Ø·ª¢T'}")
    print(f"\nT·ªïng s·ªë l·ªói: {len(all_errors)}")
    print("\nL·ªói theo lo·∫°i:")
    for error_type, count in result["errors_by_type"].items():
        print(f"  - {error_type}: {count}")
    print("="*60)
    
    return result


def main():
    """H√†m main"""
    import argparse
    import sys
    
    # Fix encoding for Windows
    if sys.platform == "win32":
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    parser = argparse.ArgumentParser(description="Cham diem video dieu lenh")
    parser.add_argument(
        "mode",
        choices=["create_golden", "evaluate"],
        help="Ch·∫ø ƒë·ªô: create_golden (t·∫°o golden template) ho·∫∑c evaluate (ƒë√°nh gi√° video)"
    )
    parser.add_argument(
        "video_path",
        type=str,
        help="ƒê∆∞·ªùng d·∫´n video (golden ho·∫∑c test)"
    )
    parser.add_argument(
        "--golden-dir",
        type=str,
        default=None,
        help="Th∆∞ m·ª•c golden template (m·∫∑c ƒë·ªãnh: data/golden_template)"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="Th∆∞ m·ª•c output (m·∫∑c ƒë·ªãnh: data/golden_template cho create_golden, data/output cho evaluate)"
    )
    
    args = parser.parse_args()
    
    video_path = Path(args.video_path)
    if not video_path.exists():
        print(f"‚ùå Video kh√¥ng t·ªìn t·∫°i: {video_path}")
        return

    # Ki·ªÉm tra nhanh ƒë·ªãnh d·∫°ng & ch·∫•t l∆∞·ª£ng video tr∆∞·ªõc khi x·ª≠ l√Ω
    is_valid, error_message = validate_video(video_path)
    if not is_valid:
        print(f"‚ùå Video kh√¥ng h·ª£p l·ªá: {error_message}")
        return
    
    if args.mode == "create_golden":
        output_dir = Path(args.output_dir) if args.output_dir else None
        create_golden_template(video_path, output_dir)
    elif args.mode == "evaluate":
        golden_dir = Path(args.golden_dir) if args.golden_dir else None
        evaluate_video(video_path, golden_dir)


if __name__ == "__main__":
    main()

